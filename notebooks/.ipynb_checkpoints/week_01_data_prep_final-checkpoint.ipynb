{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5966252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detect project root (folder containing src/) and add it to sys.path.\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def get_project_root():\n",
    "    here = Path.cwd().resolve()\n",
    "    for parent in [here] + list(here.parents):\n",
    "        if (parent / 'src' / '__init__.py').exists():\n",
    "            return parent\n",
    "    raise RuntimeError('Could not find project root containing src/__init__.py')\n",
    "\n",
    "ROOT = get_project_root()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "print('✅ Project root:', ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c420a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import utilities and define canonical paths.\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import DATA_RAW, FIGURES, ensure_dir, RANDOM_STATE\n",
    "from src.io import load_nsl_kdd_raw, save_joblib\n",
    "from src.prep import build_preprocessor\n",
    "\n",
    "DATA_PROCESSED = ROOT / 'data' / 'processed'\n",
    "FIG_DIR = ensure_dir(FIGURES)\n",
    "ensure_dir(DATA_PROCESSED)\n",
    "RAW_FILE = DATA_RAW / 'NSL-KDD.raw'\n",
    "print('RAW_FILE:', RAW_FILE)\n",
    "print('DATA_PROCESSED:', DATA_PROCESSED)\n",
    "print('FIG_DIR:', FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699efa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load raw dataset and validate required columns.\n",
    "df = load_nsl_kdd_raw(RAW_FILE)\n",
    "assert 'label' in df.columns, 'The raw file must include the label column.'\n",
    "for col in ['protocol_type','service','flag']:\n",
    "    assert col in df.columns, f'Missing categorical feature: {col}'\n",
    "print('Rows:', len(df), '| Columns:', len(df.columns))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize labels and coerce numerics. Keep categoricals as-is.\n",
    "df['label'] = df['label'].astype(str).str.rstrip('.')\n",
    "categorical = ['protocol_type','service','flag']\n",
    "numeric = [c for c in df.columns if c not in categorical + ['label']]\n",
    "for c in numeric:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "df[numeric] = df[numeric].fillna(0.0)\n",
    "\n",
    "# Map attack labels to high-level family.\n",
    "family_map = {\n",
    "    'normal':'normal','neptune':'dos','smurf':'dos','back':'dos','pod':'dos','teardrop':'dos','land':'dos','apache2':'dos','udpstorm':'dos','processtable':'dos','worm':'dos',\n",
    "    'ipsweep':'probe','nmap':'probe','portsweep':'probe','satan':'probe','mscan':'probe','saint':'probe',\n",
    "    'guess_passwd':'r2l','ftp_write':'r2l','imap':'r2l','phf':'r2l','multihop':'r2l','warezmaster':'r2l','warezclient':'r2l','spy':'r2l','xlock':'r2l','xsnoop':'r2l','snmpguess':'r2l','snmpgetattack':'r2l','httptunnel':'r2l','named':'r2l','sendmail':'r2l',\n",
    "    'buffer_overflow':'u2r','loadmodule':'u2r','perl':'u2r','rootkit':'u2r','ps':'u2r','sqlattack':'u2r','xterm':'u2r'\n",
    "}\n",
    "df['family'] = df['label'].map(family_map).fillna('other')\n",
    "print(df['family'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stratified train/test split by family.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['label','family'])\n",
    "y = df['family']\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "print('Train/Test:', X_train_df.shape, X_test_df.shape)\n",
    "print('Train families:', y_train.value_counts().to_dict())\n",
    "print('Test families:',  y_test.value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build ColumnTransformer and fit-transform.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "categorical = ['protocol_type','service','flag']\n",
    "numeric = [c for c in X_train_df.columns if c not in categorical]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False), categorical),\n",
    "    ('num', StandardScaler(with_mean=True, with_std=True), numeric),\n",
    "], remainder='drop', verbose_feature_names_out=False)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train_df)\n",
    "X_test  = preprocessor.transform(X_test_df)\n",
    "print('X_train shape:', X_train.shape, '| X_test shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f89ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save artifacts to data/processed with absolute repo path.\n",
    "np.save(DATA_PROCESSED / 'X_train.npy', X_train)\n",
    "np.save(DATA_PROCESSED / 'X_test.npy',  X_test)\n",
    "np.save(DATA_PROCESSED / 'y_train.npy', y_train.to_numpy())\n",
    "np.save(DATA_PROCESSED / 'y_test.npy',  y_test.to_numpy())\n",
    "\n",
    "from joblib import dump\n",
    "dump(preprocessor, DATA_PROCESSED / 'preprocessor.joblib')\n",
    "print('✅ Saved: X_train.npy, X_test.npy, y_train.npy, y_test.npy, preprocessor.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c42850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Demonstrate robust loading (fixes 'Invalid argument' errors).\n",
    "Xt = np.load(DATA_PROCESSED / 'X_test.npy', allow_pickle=False)\n",
    "yt = np.load(DATA_PROCESSED / 'y_test.npy', allow_pickle=False)\n",
    "print('Loaded shapes:', Xt.shape, yt.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
