---
title: "Anomaly Detection in Network Traffic Using NSL-KDD Dataset"
subtitle: "Proposal"
author: 
  - name: "Team 7 - Mehran Tajbakhsh"
    affiliations:
      - name: "College of Information Science, University of Arizona"
description: "The goal of this project is to detect anomalies in network traffic data using a combination of statistical and machine learning techniques.<br>
Anomalies, or outliers, are data points that deviate significantly from normal behavior. In cybersecurity contexts, these anomalies often correspond to intrusions, attacks, or fraudulent activities.<br>
I will use the NSL-KDD dataset, a well-established benchmark for evaluating intrusion detection systems (IDS). Through a structured process of exploratory data analysis, statistical anomaly detection, and machine learning modeling, this project aims to build a robust anomaly detection framework capable of identifying malicious network activity.<br>
The actual NSL-KDD dataset is fairly large (nearly 4 million records). I will be using a smaller version of the data that is a 10% subset randomly sampled from the whole data.<br>
Finally, I will compare performance across these methods and evaluate their ability to correctly flag network intrusions as anomalies.
"
format:
  html:
    code-tools: true
    code-overflow: wrap
    code-line-numbers: true
    embed-resources: true
editor: visual
code-annotations: hover
execute:
  warning: false
jupyter: python3
---

```{python}
#| label: load-pkgs
#| message: false
#| output: false
#| echo: false
import pandas as pd
from pathlib import Path
from myst_nb import glue
```

## Dataset

```{python}
#| label: load-dataset
#| echo: false
#| message: false
#| output: false


data_path = Path("./data/NSL-KDD.data_10_percent_corrected")

base_cols = [
    "duration","protocol_type","service","flag","src_bytes","dst_bytes",
    "land","wrong_fragment","urgent","hot","num_failed_logins","logged_in",
    "num_compromised","root_shell","su_attempted","num_root","num_file_creations",
    "num_shells","num_access_files","num_outbound_cmds","is_host_login",
    "is_guest_login","count","srv_count","serror_rate","srv_serror_rate",
    "rerror_rate","srv_rerror_rate","same_srv_rate","diff_srv_rate",
    "srv_diff_host_rate","dst_host_count","dst_host_srv_count",
    "dst_host_same_srv_rate","dst_host_diff_srv_rate",
    "dst_host_same_src_port_rate","dst_host_srv_diff_host_rate",
    "dst_host_serror_rate","dst_host_srv_serror_rate",
    "dst_host_rerror_rate","dst_host_srv_rerror_rate"
]

tmp = pd.read_csv(data_path, header=None)
if tmp.shape[1] == 42:
    tmp.columns = base_cols + ["label"]
elif tmp.shape[1] == 43:
    tmp.columns = base_cols + ["label","difficulty"]
else:
    raise ValueError(f"Unexpected column count {tmp.shape[1]} for KDD 10% file.")

df = tmp
df["label"] = df["label"].astype(str).str.strip().str.lower()

def map_family(lbl: str) -> str:
    if lbl == "normal.": return "normal"
    l = lbl
    if any(x in l for x in ["neptune","smurf","back","teardrop","pod","land","apache2","udpstorm","processtable","worm","mailbomb"]):
        return "DoS"
    if any(x in l for x in ["satan","ipsweep","nmap","portsweep","mscan","saint"]):
        return "Probe"
    if any(x in l for x in ["guess_passwd","ftp_write","imap","phf","multihop","warezmaster","warezclient","spy","xlock","xsnoop","snmpgetattack","snmpguess","httptunnel","sendmail","named","worm_r2l"]):
        return "R2L"
    if any(x in l for x in ["buffer_overflow","loadmodule","perl","rootkit","sqlattack","xterm","ps","httptunnel_u2r"]):
        return "U2R"
    return "attack_other"

df["family"] = df["label"].apply(map_family)

# ---- Inline stats (suppress display) ----
n_rows, n_cols = df.shape
n_features = n_cols - (2 if "difficulty" in df.columns else 1)

glue("n_rows", n_rows, display=False)
glue("n_cols", n_cols, display=False)
glue("n_features", int(n_features), display=False)
glue("has_difficulty", "yes" if "difficulty" in df.columns else "no", display=False)

# Family percentages + counts
fam_pct = df["family"].value_counts(normalize=True).mul(100)
fam_cnt = df["family"].value_counts()

for fam in ["normal","DoS","Probe","R2L","U2R"]:
    glue(f"p_{fam}", float(fam_pct.get(fam, 0.0)), display=False)
    glue(f"c_{fam}", int(fam_cnt.get(fam, 0)), display=False)

```
The **NSL-KDD** dataset is an improved successor to **KDD Cup 1999**, designed to mitigate key issues such as redundant records and extreme class imbalance.<br>It comprises **network connection records** with **41 features** (transport/application protocol, service, flag indicators, traffic statistics, etc.) and a label indicating **normal** or one of several **attack types** grouped into four categories: **DoS**, **Probe**, **R2L**, and **U2R**.

```{python}
#| label: Dataset Summary
#| echo: false
#| message: false

md = f"""
This analysis uses the 10% of NSL-KDD corrected file with {n_rows} rows and {n_cols} columns.

In the context of intrusion detection, the dataset encompasses four main families of 
attack behaviors: Denial of Service (DoS), Probe, Remote to Local (R2L),
and User to Root (U2R): 

- normal: {df["family"].value_counts(normalize=True).mul(100).get("normal", 0):.2f}% (n = {df["family"].value_counts().get("normal", 0)})
- DoS: {df["family"].value_counts(normalize=True).mul(100).get("DoS", 0):.2f}% (n = {df["family"].value_counts().get("DoS", 0)})
- Probe: {df["family"].value_counts(normalize=True).mul(100).get("Probe", 0):.2f}% (n = {df["family"].value_counts().get("Probe", 0)})
- R2L: {df["family"].value_counts(normalize=True).mul(100).get("R2L", 0):.2f}% (n = {df["family"].value_counts().get("R2L", 0)})
- U2R: {df["family"].value_counts(normalize=True).mul(100).get("U2R", 0):.2f}% (n = {df["family"].value_counts().get("U2R", 0)})
"""

print(md)

```

Why this dataset? <br> It’s the canonical benchmark for intrusion/anomaly detection and complements NSL-KDD, which addresses redundancy/imbalance issues. Its size, variety of features (categorical + numeric), and labeled attacks make it ideal for comparing statistical (Z-Score, Elliptical Envelope, LOF, DBSCAN) and ML detectors (Isolation Forest, OC-SVM, Deep Autoencoders).

## Questions

1. How effectively can statistical anomaly detection methods identify malicious network traffic within the NSL-KDD dataset?<br>
Or more specifically, which unsupervised techniques — such as Z-Score, Elliptic Envelope, Local Outlier Factor (LOF), and DBSCAN — perform best in distinguishing normal traffic from various attack families (DoS, Probe, R2L, and U2R)? <br>

2. How does the performance of machine learning–based intrusion detection models compare to traditional statistical anomaly detectors?<br>
Or more specifically, which algorithms — including Random Forest, Support Vector Machine (SVM), Isolation Forest, and Deep Autoencoders — achieve higher accuracy, precision, and recall when detecting network intrusions, and what trade-offs exist in terms of interpretability and computational cost?

## Analysis plan

**Week 1 –** Problem Definition & Data Preparation
The first week focuses on defining the objectives of anomaly detection within the NSL-KDD dataset. The dataset will be loaded, inspected, and preprocessed to ensure analytical readiness. Tasks include handling missing values, encoding categorical features, and scaling numerical variables.
Deliverables: Data preparation notebook and summary report.

**Week 2 –** Exploratory Data Analysis (EDA)
This phase aims to understand data distributions, feature correlations, and patterns of normal versus attack traffic. Visualization techniques will be applied to highlight key discriminative features and potential sources of anomaly.
Deliverables: EDA notebook with visual insights and descriptive summaries.

**Week 3 –** Statistical Anomaly Detection Methods
In this stage, classical statistical methods for anomaly detection will be implemented, including Z-Score, Elliptical Envelope, Local Outlier Factor (LOF), and DBSCAN. Their performance in identifying abnormal network behaviors will be analyzed and compared.
Deliverables: Statistical anomaly detection notebook and comparative summary.

**Week 4 –** Machine Learning–Based Methods
Modern learning-based detectors will be explored using Isolation Forest, One-Class SVM, and Deep Autoencoders. Models will be tuned for optimal performance, and detection boundaries will be visualized to interpret decision behavior.
Deliverables: ML anomaly detection notebook and evaluation metrics.

**Week 5 –** Model Evaluation and Comparison
All implemented methods will be assessed using standard performance metrics such as Precision, Recall, F1-score, ROC-AUC, and Detection Rate. Comparative analyses and ablation studies will be performed to evaluate robustness and generalization.
Deliverables: Evaluation notebook and performance report.

**Week 6 –** Final Analysis & Reporting
The final week synthesizes results into a comprehensive assessment of the effectiveness of different anomaly detection techniques. The findings will discuss practical implications, advantages, and limitations of each approach in real-world intrusion detection scenarios.
Deliverables: Final project report and presentation slides.